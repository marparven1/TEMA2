---
title: "Hoja 4 (c): Tests Chi-cuadrado con R"
author: "Marta Venegas Pardo"
subtitle: Estadística Computacional I. Grado en Estadística
lang: es
output:
  pdf_document:
    toc: yes
    toc_depth: 3
  html_document:
    toc: yes
    toc_depth: '3'
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Ejercicio 1: Test de bondad de ajuste

Bondad de ajuste. Comprobar si un dado es correcto a partir del número de veces que ha salido cada lado.

```{r}
frecu <- c(22,21,22,27,22,36)
probs <- rep(1/6,6)
```




Utilizamos el test Chi-Cuadrado, donde comparamos lo observado frente a lo esperado.


```{r}
chisq.test(frecu, p=probs)
```

Acepto que sigue ese modelo probabilístico (equiprobabilidad).

# Ejercicio 2: Distribución uniforme discreta

Por defecto se compara con la unif. discreta. En el siguiente ejemplo se trata de ver si en un texto las apariciones de las letras E,T,N,R,O se distribuyen según los valores conocidos en inglés.

```{r}
x <-c(100,110,80,55,14)
probs <-c(29, 21, 17, 17, 16)/100
```

Si sólo me dieran los datos en lugar de la frecuencia, tendría que hacer la tabla de frecuencias y ya hacer el ejercicio.

```{r}
chisq.test(x,p=probs)
```

Tenemos un p-valor muy extremo, existe una gran diferencia entre los valores observados y esperados. 
Se rechaza que la muestra siga el modelo teórico.


# Ejercicio 3: Ley uniforme discreta, muestras

En la siguiente simulación se ilustra la calidad de la aproximación.
Se generan M muestras de tamaño n de una ley Uinforme discreta.

```{r }
probabi<- c(0.03,0.25,0.45,0.27)
sum(probabi)
set.seed(12345)
n<-50 #tamaño muestral
n*probabi  #Se cumplen las condiciones 
M<-5000
estad<- numeric(M)
```


## Generar la muestra i, calcular la tabla y obtener el estadístico chi-cuadrado.

```{r message=FALSE , warning=FALSE}
for (i in 1:M) {
  x=sample(1:4,size = n, prob = probabi,rep=T)
  resultado= c(sum(x==1),
               sum(x==2),
               sum(x==3),
               sum(x==4))
  estadistico_chi=chisq.test(resultado, p=probabi)
  estad[i] =estadistico_chi$statistic
}
```

Tenemos estad con 5000 valores

```{r}
head(estad)
```

## Histograma del estadístico y densidad de la chi-cuadrado.


```{r}
hist(estad, breaks = 30, probability = TRUE,
     main="Valores del estadístico Chi-Cuadrado",ylim = c(0,0.25))
curve(dchisq(x,length(probabi)-1), col="blue",lwd=2,add=TRUE)
```


# Ejercicio 4: Tablas de contingencia: Test

## Tests de independencia en tablas de contingencia.

```{r echo=TRUE}
#save(TRABAJO,AUTOESTIMA,file="ej04.RData")
load("ej04.RData")
tabla<- table(TRABAJO,AUTOESTIMA)
tabla
```


## Apartado a

Comprobación del p-valor y dibujar la distribución teórica, el cuantil y el valor observado.


H0 es la independencia de las muestras.

```{r}
resul=chisq.test(tabla)
resul

```

Rechazo H0, las muestras están relacionadas. Lo razonamos debido al p-valor.

```{r}
resul$expected
```
```{r}
resul$observed
```

Calculamos el estadístico de manera manual. 

- Forma 1:

```{r}
sum(resul$residuals^2)
```

- Forma 2:

```{r}
sum((resul$observed-resul$expected)^2/(resul$expected))
```



## Cálculo del p-valor:

```{r}
nr=nrow(tabla)
nc=ncol(tabla)
gr_lib=(nr-1)*(nc-1)
1-pchisq(resul$statistic,df=gr_lib)
```


## Dibujar la fdd para la Chi-Cuadrado con esos grados de libertad.

```{r}
curve(dchisq(x,gr_lib),0,30,1000,lwd=2,col="blue")
abline(v=resul$statistic,col="red")
abline(v=qchisq(0.95,gr_lib), col="green")
```

El p-valor es la probabilidad de que quede a la derecha, que como vemos es muy pequeña.
La línea verde me muestra donde se encuentra el estadístico,donde empieza la región crítica.


# Ejercicio 5: Librería vcd

## Tests de independencia en tablas de contingencia (Uso de la librería vcd).

```{r}
load("GSS.RData")
GSS
```



## Tabla de frecuencias con el paquete básico.

```{r}
tabla_GSS=xtabs(count ~ sex+party , data = GSS)
tabla_GSS
```

## Test Chi_Cuadrado.

```{r}
chisq.test(tabla_GSS)
```

## Uso paquete vcd

Instalo el paquete vcd

```{r}
library(vcd)
assocstats(tabla_GSS)
#CrossTable(GSStab)
```
Me calcula todas las medidas de asociación. Me interesa el p-valor de pearson.

## Gráfico.
```{r}
assocplot(tabla_GSS, col=c("blue","pink"),
          main="Azul=Obs>Esp , Rosa= Obs<Esp")
```
Nos presenta la tabla de forma gráfica, mostrando como están distribuidas las categorías.

Parece que existe un comportamiento relacionado con el sexo.




# Ejercicio 6: Té


Una dama británica sostenía que era capaz de adivinar si en un té con leche se ha vertido antes el té o la leche. 

Para ello se realizó un experimento donde se le pidió que lo adivinara para 8 tazas:

$$
\begin{array}{l}
H_0:P[dice leche=/leche]=P[dice té/leche] \\
H_1:P[dice leche=/leche]>P[dice té/leche]
\end{array} 
$$



```{r}
pruebate <-
  matrix(c(
    3,1,1,3), nrow = 2,
    dimnames = list(Predice = c("Leche", "Té"),
                    Verdad = c("Leche", "Té")))
pruebate
```

## Test ChiCuadrado (a pesar de que las observadas no son mayores o iguales a 5)

```{r}
res=chisq.test(pruebate)
res
```

No hay razones para rechazar.

```{r}
res$expected
```
Lo observado no se espera mucho de lo esperado.

## Test exacto de Fisher
En esta situación es más apropiado aplicar el Test exacto de Fisher:

```{r}
fisher.test(pruebate, alternative = "greater")
```


# Ejercicio 7: Gafas y antecedentes.

```{r}
gafasante <-
  matrix(c(1, 8, 5, 2), nrow = 2,
         dimnames = list(Gafas = c("Sí", "No"),
                         Antecedentes = c("Sí", "No")))
gafasante
```
Se requiere contrastar que H0: Variables categóricas independientes.

```{r}
chisq.test(gafasante) # Muestres independientes.
```

## Test de fisher:

```{r}
fisher.test(gafasante)
```
Rechazo H0, existe un comportamiento diferente entre las variables

# Ejercicio 8: Datos relacionados

## Test de McNemar (datos relacionados). 

Datos relacionados, por ejemplo antes-después.

Dos encuestas con un mes de separación, se pregunta a cada uno de los 1600 encuestados si aprueba o desaprueba a un gobernante.

```{r}
datos <- matrix(c(794, 86, 150, 570), nrow = 2,
       dimnames = list("Primera encuesta" = c("Aprueba", "Desaprueba"),
                       "segunda encuesta" = c("Aprueba", "Desaprueba")))
datos
```


Muestras dependientes


```{r}
mcnemar.test(datos)
```


El p-valor es muy pequeño y menor que alpha, rechazo H0: las muestras se comportan igual. Es decir, ha habido un cambio de opcinión de una encuesta a otra.


