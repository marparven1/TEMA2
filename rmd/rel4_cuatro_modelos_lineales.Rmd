---
title: "Hoja 4 (d): Modelos lineales con R"
author: "Departamento de Estadística e Investigación Operativa. Universidad de Sevilla"
subtitle: Estadística Computacional I. Grado en Estadística
lang: es
output:
  pdf_document: 
    toc: no
  html_document: 
    toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



## Ejercicio 1

ANOVA de un factor. 

El fichero de datos "scores.txt" contiene la puntuación obtenida en una prueba de nivel de inglés para 40 alumnos. Se han considerado 4 academias, de cada una de las cuales han sido seleccionados aleatoriamente 10 alumnos. Se trata de estudiar si existen diferencias significativas entre las puntuaciones medias dependiendo de la academia.

```{r}
scores=read.table(file="scores.txt", header=TRUE)
head(scores)
```


Lo representamos:
```{r}
boxplot(scores$Score ~scores$Grupo)
```
Nos lo representa para cada grupo.

¿Son significativas las diferencias que vemos gráficamente?

Las medias para cada academia:

```{r}
library(tidyverse)
scores %>% 
  group_by(Grupo) %>% 
  summarise(
    Media = mean(Score)
  )
```

Para estudiar la normalidad:

### Test de Shapiro

```{r}
shapiro.test(
  scores %>% 
    filter(Grupo =="A") %>%
    select(Score) %>%
    pull())
shapiro.test(
  scores %>% 
    filter(Grupo =="B") %>%
    select(Score) %>%
    pull())
shapiro.test(
  scores %>% 
    filter(Grupo =="C") %>%
    select(Score) %>%
    pull())
shapiro.test(
  scores %>% 
    filter(Grupo =="D") %>%
    select(Score) %>%
    pull())
```

Si aceptamos.

Vamos a hacerlo de una vez:

```{r}
scores %>% 
  group_by(Grupo) %>% 
  summarise(
    pvalor.shapiro = shapiro.test(Score)$p.value # Le paso el TShapiro a la vble score pero selecciono solo el p-valor o podría el estadístico. Si no selecciono nada me devuelve una lista y da error.
  )
```


Con purrr
```{r}
library(purrr)
scores %>% 
  split(.$Grupo) %>% 
  map_dbl(~shapiro.test(.x$Score)$p.value)
```
Aceptamos la Normalidad en las cuatro academias.

Estudiamos la homocedasticidad o igualdad de varianzas.

```{r}
library(car)
leveneTest(scores$Score~scores$Grupo, center="mean")
```
Aceptamos la hipótesis de homocedasteceidad.


Podemos aplicar los test paramétricos ANOVA.

```{r}
anova1factor=aov(Score~Grupo , data=scores)
anova1factor
summary(anova1factor)
```

Rechazo H0: medias iguales. Las academias no tienen la misma valoración.

```{r}
cbind(Coef=coef(anova1factor),confint(anova1factor))
```

Coge el grupo A como referencia. El B y C están por debajo mñás de un punto en media, y el D tiene una media muy parecida.

En el grupo B no está el 0, la diferencia es muy significativa. Con los C y D está el 0.

Comparaciones multple: Métodos de Tukey y Ducan

Tukey
```{r}
TukeyHSD(x=anova1factor, conf.level = 0.95)
```
Aceptamos o rechazamos que sean más grandes las medias.
Difernecias significativas: B-A y D-B (por los p-valores)

Duncan
```{r}
library(agricolae)
resD=duncan.test(anova1factor,trt="Grupo", console=TRUE)
```
```{r}
plot(resD)
```

Aparecen dos grupos de academias: D-A y C-B.

La estamos viendo de forma ordenada. La mejor media es la D. La A es menor pero podría estar en el mismo grupo. El C viene por detrás y luego por último el B


$$
H_0 : \mu_1 = \mu_2 =\mu_3=\mu_4
$$

Si hubiéramos usado la estadística no paramétrica, sería a través de:

```{r}
kruskal.test(scores$Score~ scores$Grupo)
```




## Ejercicio 2

ANOVA de dos factores.

A fin de investigar el efecto del fármaco Rhitalin sobre los niños hiperactivos se tomó una muestra de 4 niños para cada uno de los cruces de los dos siguientes factores: Tipo de niño (normal e hiperactivo) y medicamento administrado (Placebo y Rhitalin). Para cada niño se midió un índice de actividad.

Factores: Son variables categóricas
Muestras independientes pero para el cruce de dos factores.
```{r}
indice<-c(50,45,55,52,67,60,58,65,70,72,68,
          75,51,57,40,55)
niño<- gl(2,8)
levels(niño)<- c("Normal","Hiperactivo")
tratamiento<- gl(2,4,16)
levels(tratamiento)<- c("Placebo","Rhitalin")
data.frame(niño,tratamiento,indice)
datos2=data.frame(niño,tratamiento,indice)
```

Solución:

```{r}
plot(indice~niño + tratamiento)
```

Interacciones:

```{r}
interaction.plot(niño, tratamiento ,indice)
interaction.plot(tratamiento,niño ,indice)
```
Vemis que el únduce de hioeractividad aumenta con placebo, pero con el medicamento desciende. Parece que hay relación.



```{r}
interaction.plot(tratamiento,niño ,indice)
```
Interpretar



Test de Anova de dos factores (si es paramétrico)
```{r}
modelo2_factores=lm(indice~niño * tratamiento) # Producto en la fórmula (Le digo que tambien considere las interacciones)
anova(modelo2_factores)
```


```{r}
summary(modelo2_factores)
```

Estudio las hipotesis
```{r}
shapiro.test(modelo2_factores$residuals)
```

Acepto H0.
Si rechazo, técnicas no paramétricas.




## Ejercicio 3

Regresión Lineal Simple.

```{r}
x <- c(18,23,25,35,65,54,34,56,72,
       19,23,42,18,39,37)  
#x=Edad
y <-c(202,186,187,180,156,169,174,172,
      153,199,193,174,
      198,183,178) 
#y=Máximo de "frecuencia cardíaca"
```


```{r}
library(tidyverse)
library(tibble)
datos3=tibble(Edad=x,FCardiaca=y)
head(datos3)
```


Nube puntos y superponer la recta de mínimos cuadrados.

```{r}
library(ggrepel)
datos3 %>% 
  ggplot(aes(x=Edad , y=FCardiaca, label=row.names(.)))+
  geom_point() + #Diagrama de dsipersion
  geom_smooth(method="lm")+
  geom_text_repel()
```
Vamos a obtener el modelo lineal.
```{r}
modelo=lm(FCardiaca~Edad, data=datos3)
summary(modelo)
```


Se puede estudiar el cumplimiento de las hipotesis del modelo de regrsión lineal con ayuda.
```{r}
plot(modelo)
```


Comentar.

El último gráfico estudia la existencia de posibles outliers, parece que no hay ningun punto que se salga de la zona.

## Ejercicio 4

Regresión Lineal Múltiple. 


```{r}
library(ISLR) #para acceder a Hitters
data(Hitters)
# ?Hitters
summary(Hitters)
```



```{r}
dim(Hitters)
```

Valores NA en el dataset:
```{r}
length(which(is.na(Hitters)))
```

Lo que no sabemmos es si es sobre la misma variable o no. Podemos calcular los valores NA para cada columna con sapply 
```{r}
sapply(Hitters, function(x) sum(is.na(x)))
```
Recorre cada columna y suma los unos que haya. Como vemos únicamente en la variable Salario.


Vamos a trabajar sin las filas que tienen valores NA:

```{r}
Hitters2=na.omit(Hitters)
```


Vamos a realizar un análisis de regresión lineal múltiple sobre la variable Salario ( dependiente )

```{r}
boxplot(Hitters2$Salary)
```
Existen vastantes valores outliers, distribución muy asimétrica.

```{r}
boxplot(log(Hitters2$Salary))
```

Decidimos trabajar con la variable transformada (log(Salary))

El modelo que vamos a considerar es:

```{r}
str(Hitters2)
```
Las variables categóricas son de tipo factor (asigna valores numéricos a cada categoría)

```{r}
(modeloRLM=lm(data=Hitters, formula= log(Salary)~.))
modeloRLMpeor=lm(data=Hitters, formula= Salary~.)
```

```{r}
summary(modeloRLM)
```

Las variables significativas son las que tienen asteriscos, rechazo que sea, 0 esos coeficientes.

```{r}
# summary(modeloRLMpeor)
```

Para estudiar la validez de las hipótesis:

```{r}
plot(modeloRLM)
```
```{r}
cuales=c("-Mike Schmidt" , "-Terry Kennedy" , "-Steve Sax")
Hitters2red=Hitters2[rownames(Hitters2) %in% cuales , ]
Hitters2red
```

Vamos a ver si mejora la regresión quitando a estos individuos

```{r}
Hitters3=Hitters2[!(rownames(Hitters2) %in% cuales),]
(modeloRLM3=lm(data=Hitters3, formula= log(Salary)~.))
```
```{r}
summary(modeloRLM3)
```

```{r}
plot(modeloRLM3)
```


## Ejercicio 5

Regresión Lineal Múltiple.

El fichero de datos "Advertising.csv"" contiene las ventas de un producto en 200 mercados diferentes junto con los presupuestos de publicidad en cada mercado en tres medios: televisión, radio y prensa. 

El objetivo es construir un modelo de regresión lineal múltiple para predecir las ventas del producto en función de los gastos en publicidad.

Variables en el archivo: Caso; TV, Radio, Prensa (miles de dólares) y las Ventas (miles de unidades).

### Apartado a


Incrementar en mil dólares el gasto publicitario en TV conlleva, por término medio, aumentar en 0.046*1000= 46 unidades las ventas del producto (suponiendo que el gasto publicitario en Radio no cambia). 

Si se incrementa en mil dólares el gasto publicitario en la Radio, cabe esperar que las ventas aumenten en 188 unidades, suponiendo fijo el gasto en TV.

Los gastos publicitarios en TV y Radio explican el 89.72% de la varianza de las Ventas del producto mediante este modelo.


### Solución
```{r}
library(readr)
Advertising <- read_csv("rmd/Advertising.csv")
```

```{r}
dim(Advertising)
summary(Advertising)
```

En este dataset no hay valores faltantes o NA, ya que summary nos lo da.



```{r}
length(which(is.na(Advertising)))
```

```{r}
boxplot(Advertising$Ventas)
```
No es necesario utilizar transformaciones de "Ventas", ya que no existen valores outliers.


El modelo de regresión lineal simple que planteamos:
```{r}
resRML=lm(data = Advertising,formula = Ventas~TV+Radio+Prensa)
summary(resRML)
```
R cuadrado es alto, la única variable que no interviene es prensa. ¿Se verá muy afectado el modelo si quito esta variable?

```{r}
resRML1=lm(data = Advertising,formula = Ventas~TV+Radio)
summary(resRML1)
```

Tenemos el mismo R, usarla o no no mejora el comportamiento del modelo lineal.

Para comparar modelos lineales no es conveniente usar el valor de Rcuadrado (tiene en cuenta el número de variables predictoras).

Mejor usar los criterios de información:

- AIC (de Akaike)
- BIC (Bayesiano)

```{r}
AIC(resRML)
AIC(resRML1)
```

```{r}
BIC(resRML)
BIC(resRML1)
```


Se observa que el modelo "resMRL1" se comporta mejor según los dos valores, al presentar un valor menor.

```{r}
plot(Advertising[,-1])
```
Vamos a ver la correlación 
```{r}
cor(Advertising[,-1])
```

```{r}
plot(resRML1)
```

Se pueden obtener intervalos de confianza para los coeficientes de regresión:

```{r}
confint(resRML1) # Podemos cambiar el nivel.
```

Para realizar predicciones:

```{r}
predict(resRML1)
```
Para hacer predicciones sobre datos nuevos:

```{r}
Advertising
(datos.nuevos = data.frame(
 TV = c(rep(seq(100,300, by = 50), 5)),
 Radio = c(rep(1:5, each = 5)*10)

))
```
Para predecir:
```{r}
predict(resRML1, datos.nuevos, interval = "confidence")
```
Para datos nuevos mejor usar el dato "prediction":

```{r}
predict(resRML1, datos.nuevos, interval = "prediction")
```


## Ejercicio 6

Regresión cuadrática. 

En 1609 Galileo demostró que la trayectoria de un cuerpo cayendo con una horizontal componente es una parábola. En el curso de ganar conocimiento de este hecho, estableció un experimento que midió dos variables, una altura y una distancia, produciendo los siguientes datos.

```{r}
dist = c(253, 337,395,451,495,534,574)
height = c(100,200,300,450,600,800,1000)
```


### Solución:

Regresión cuadrática:

```{r}
lm.2=lm(dist~height+I(height^2)) # Añado término de 2 grado.
summary(lm.2)
```
Regresión cúbica o de grado 3:

```{r}
lm.3=lm(dist~height+I(height^2)+ I(height^3)) 
summary(lm.3)
```
Comparamos con la de grado 1:

```{r}
lm.1=lm(dist~height) 
summary(lm.1)
```
```{r}
AIC(lm.1)
AIC(lm.2)
AIC(lm.3)
```

El mejor modelo es el de regresión cúbica.